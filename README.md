# CS98BIT

To get a better understanding on the concept of online algorithms, specifically the List Update Problem, my first task was to read a collection of research papers on the topic what were written by previous researchers on the topic. The List Update Problem is considered to be an extremely crucial problem in the realm of online computation. First, we must define what an online algorithm is in itself. As outlined in Online Computation and Competitive Analysis by Borodin and El-Yaniv an algorithm is considered online when each decision must be made off past events without secure information regarding the future. Online algorithms also have a competitive ratio: when an algorithm is compared to an offline algorithm. It is considered competitive ratio is between its performance and the offline performance is bounded. The upper and lower bounds of an algorithm show the complexity of problems, with the upper-bound demonstrating that the online problem can never be worse than a particular ratio. The lower bound shows that the online problem can never be better than a particular ratio. Throughout this semester, my goal was to work on finding a better lower bound for the List Update Problem. 

According to A Survey of Algorithms and Models for List Update by Kamali and Lopez-Ortiz, the problem considers an unsorted list of L items. The input to the algorithm is a sequence of L requests. To serve a request item I in the sequence, a List Update Algorithm will search the list until I is found. If I is the nth item in the list, then a cost of n will be incurred in order to access I. Once the item is accessed, then the item can be moved closer to the front of the list at no extra cost. This type of move is considered a free exchange. The algorithm can also swap any two consecutive items at a cost of 1. This is known as a paid exchange. An efficient algorithm uses both free and paid exchanges, with the ultimate goal of minimizing the cost of accessing all the elements that are within the request sequence. 
Throughout the years, researchers have developed various different algorithms that look to maximize the efficiency and minimize the cost of the List Update Problem. There are several algorithms that have shown the most promise. The most common deterministic algorithms are the Move to Front algorithm, the Transpose algorithm, and the Frequency Count algorithm, with MTF having the highest competitive ratio of 2. However, the program that I developed with Professor Marc Renault focused particularly on the BIT Update Algorithm, which uses randomization to help lower its cost. Random algorithms provide an estimation of the average competitive ratio of deterministic algorithms. Deterministic algorithms do not use any randomization in their processes. Randomized algorithms will achieve a better competitive ratio than deterministic ones, but their validity is under question, because the competitive ratio does not really capture the worst-case scenarios that are made by the online algorithm. 

The BIT algorithm works as follows:
•	The algorithm assigns a bit b(x) to each item x, which is randomly set to be 0 or 1. 
•	At the time of an access to an element of x, the content of b(x) is complemented.
•	Only after the bit of b(x) has been complemented, will the contents be checked to continue the algorithm. 
o	If b(x) is equal to 1, the algorithm moves x to the front of the list. 
The BIT algorithm has a competitive ratio of 1.75 and is considered barely random. This is because the number of random bits is dependent on the list, not on the request sequence itself. Essentially, only at the beginning of the algorithm is there any randomness associated with the algorithm (when the bits are set to each item of the list). 
